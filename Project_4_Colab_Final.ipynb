{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.4.3'\n",
        "spark_version = 'spark-3.4.3'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop3.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop3\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "goX26_Sfxbpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TNgcPUpQ3_Dv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "4sHfYVNv3Qb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvfRGEdk0yDP"
      },
      "outputs": [],
      "source": [
        "# General purpose libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning and preprocessing libraries\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "\n",
        "# Spark libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType, FloatType, StringType\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import pyspark.pandas as pspd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read in the data to process"
      ],
      "metadata": {
        "id": "rH7OKxGj3aMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()\n",
        "\n",
        "# Read in the CSV into a DataFrame.\n",
        "file_path = \"original_extracted_df.csv\"\n",
        "home_df = spark.read.csv(file_path, sep=\",\", header=True)\n",
        "home_df.show()\n",
        "print(home_df.count())"
      ],
      "metadata": {
        "id": "N2rgOG2Fxpl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the Data\n",
        "\n",
        "The Target(X) is the Price and the Features(y) are all the other columns"
      ],
      "metadata": {
        "id": "HB3eZiIirWmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the non beneficial columns\n",
        "home_narrow_df = home_df.drop(\"City\",\"Street\", \"Latitude\", \"Longitude\", \"MarketEstimate\", \"Zipcode\", \"PPSq\", \"LotArea\", \"LotUnit\", \"RentEstimate\")\n",
        "home_narrow_df.show()"
      ],
      "metadata": {
        "id": "XINFOAP-Pg1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aYpCMlCigAi"
      },
      "outputs": [],
      "source": [
        "# Drop rows with NaN values\n",
        "null_replacements = [\"\", \"null\", \"None\", \"NULL\", \"nan\"]\n",
        "for col_name in home_narrow_df.columns:\n",
        "    home_narrow_df = home_narrow_df.withColumn(\n",
        "        col_name, when(col(col_name).isin(null_replacements), None).otherwise(col(col_name)))\n",
        "home_cleaned_df = home_narrow_df.dropna(how=\"any\")\n",
        "\n",
        "# Print the first few rows of the cleaned DataFrame\n",
        "print(home_cleaned_df.count())\n",
        "home_cleaned_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "home_cleaned_df.groupby(\"Area\").count().show()"
      ],
      "metadata": {
        "id": "NJS91pHwq0r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_prices = home_cleaned_df.select('price').distinct()\n",
        "distinct_prices.show()"
      ],
      "metadata": {
        "id": "CbId8g4kuEN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distinct_bedrooms = home_cleaned_df.select('bedroom').distinct()\n",
        "distinct_bedrooms.show()"
      ],
      "metadata": {
        "id": "LA4ozhsIwFcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take off the outliers of bedroom >10 and prices < 1000\n",
        "home_cleaned_df = home_cleaned_df.filter((home_cleaned_df['price'] >= 1000) & (home_cleaned_df['bedroom'] <= 10)) \\\n",
        "    .withColumn(\"index\", monotonically_increasing_id()) \\\n",
        "    .drop(\"index\")\n",
        "\n",
        "home_cleaned_df.show()\n"
      ],
      "metadata": {
        "id": "ldLeGIG3ubwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the Schema\n",
        "home_cleaned_df.printSchema()"
      ],
      "metadata": {
        "id": "5TWYH9uUQffx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert all but states to integers\n",
        "col_type_map = {\n",
        "    \"State\": StringType(),\n",
        "    \"Bedroom\": IntegerType(),\n",
        "    \"Bathroom\": FloatType(),\n",
        "    \"Area\": IntegerType(),\n",
        "    \"ConvertedLot\": FloatType(),\n",
        "    \"Price\": IntegerType()\n",
        "}\n",
        "\n",
        "home_converted_df = home_cleaned_df.select(\n",
        "  [home_cleaned_df[c].cast(col_type_map[c])\n",
        "  for c in col_type_map]\n",
        ")\n",
        "home_converted_df.printSchema()"
      ],
      "metadata": {
        "id": "St9cSOo_pn5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the PySpark DataFrame to a Pandas DataFrame using toPandas()\n",
        "home_pd_df = home_converted_df.toPandas()\n",
        "print(home_pd_df.shape)\n",
        "home_pd_df.head()"
      ],
      "metadata": {
        "id": "IUdcB3yJ0e6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode the variables features using get_dummies"
      ],
      "metadata": {
        "id": "fLcLKx_e4GVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dummies for states\n",
        "home_encoded_df = pd.get_dummies(home_pd_df)\n",
        "home_encoded_df.head()"
      ],
      "metadata": {
        "id": "aPIKSvA00y0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the Features (y) from the Target(X)\n",
        "y = home_encoded_df[\"Price\"]\n",
        "\n",
        "X = home_encoded_df.drop(columns=\"Price\")"
      ],
      "metadata": {
        "id": "KERh_Z2u2P1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample data for the Features\n",
        "X[:5]"
      ],
      "metadata": {
        "id": "dN73eTTr2qeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample data for the target\n",
        "y[:5]\n"
      ],
      "metadata": {
        "id": "C2EtvIEecsiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separate the data into Training and Testing subsets"
      ],
      "metadata": {
        "id": "vyKDPpMZ324a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QBr2KTKfXsN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "X_scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "BLadMGX_8O7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the scaler\n",
        "X_scaler.fit(X_train)"
      ],
      "metadata": {
        "id": "w96beeGLz-vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "XBh35nLC0DNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Regression Model**\n",
        "Random Forest Regression is an ensemble learning technique based on Decision Tree Regression. It combines the predictions of multiple individual decision trees to improve the overall predictive accuracy and reduce overfitting. Random Forest Regression is a powerful and widely used regression technique suitable for a wide range of regression problems, including prediction, forecasting, and modeling complex systems.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iXHEFgV2PlA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Random Forest regression model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)"
      ],
      "metadata": {
        "id": "W4jcM7k4QlYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model and use .ravel()on the \"y_train\" data.\n",
        "rf_model.fit(X_train, y_train.ravel())"
      ],
      "metadata": {
        "id": "-0JqV3dfQWo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions using the testing data\n",
        "predictions = rf_model.predict(X_test)\n",
        "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
        "results.head(10)"
      ],
      "metadata": {
        "id": "V2xKbP8oYpN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Random Forest regression model\n",
        "y_pred = rf_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std_dev = np.std(y_test - y_pred)"
      ],
      "metadata": {
        "id": "qIJkiL5YQWtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "print(f\"Standard Deviation: {std_dev}\")"
      ],
      "metadata": {
        "id": "UZJRuWNrUYU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model seems to have moderate performance. While the R^2 score  of approximately 0.65 explains approximately the variance in the target variable. The model suggests moderate prediction."
      ],
      "metadata": {
        "id": "eTSxzQPHx0oc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting predicted vs actual prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test.ravel(), y_pred.ravel(), color='blue') # Flatten y_test and y_pred\n",
        "\n",
        "# Extract the min and max from the y_test array directly\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted Home Prices Random Forest')\n",
        "plt.savefig(\"random_forest.png\") # Save the image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BkIacEjvKCw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display top 10 feature importances\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1][:10]  # Select top 10 indices\n",
        "# Instead of X.columns, use the 'features' variable that already contains the column names\n",
        "features = X.columns\n",
        "features = features\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Top 10 Feature Importances\")\n",
        "plt.bar(range(10), importances[indices], align=\"center\")  # Display only top 10\n",
        "plt.xticks(range(10), [features[i] for i in indices.astype(int)], rotation=90)\n",
        "plt.xlim([-1, 10])  # Limit x-axis to top 10\n",
        "plt.tight_layout()  # Adjust layout for better fit\n",
        "plt.savefig(\"top_10_feature_importances.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6CBQqQDieW0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree Regression Model**\n",
        "Decision Tree Regression is a supervised machine learning algorithm used for regression tasks. It works by recursively partitioning the feature space into regions and fitting a simple model (usually a constant value) to each region."
      ],
      "metadata": {
        "id": "kCSYkaV9VLIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Decision Tree regression model\n",
        "decision_model = DecisionTreeRegressor(random_state=42)"
      ],
      "metadata": {
        "id": "U03iBXmyHR8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the data into the model\n",
        "decision_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "p1c7V75rRFxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions using the testing data\n",
        "predictions = decision_model.predict(X_test)\n",
        "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
        "results.head(10)"
      ],
      "metadata": {
        "id": "pchtL579RGBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = decision_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std_dev = np.std(y_test - y_pred)"
      ],
      "metadata": {
        "id": "Gumy9DY5RF7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "print(f\"Standard Deviation: {std_dev}\")"
      ],
      "metadata": {
        "id": "YR487mutUSuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RÂ² score being negative (50%) suggests that the model performs worse than a horizontal line, which is not uncommon in some scenarios but generally indicates a poor fit."
      ],
      "metadata": {
        "id": "HVp7tDLPkHfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting predicted vs actual prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], 'k--', lw=2)\n",
        "\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted Home Prices Decision Tree')\n",
        "plt.tight_layout()  # Adjust layout for better fit\n",
        "plt.savefig(\"actual_vs_predicted_prices.png\") # Save the image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5OZT2_D5JxN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linear Regression Model**\n",
        "\n",
        "Linear Regression is a fundamental supervised machine learning algorithm used for predictive analysis. It models the relationship between a dependent variable (target) and one or more independent variables (features) by fitting a linear equation to observed data"
      ],
      "metadata": {
        "id": "_8yOG8u9VXUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Train, Test, Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ],
      "metadata": {
        "id": "yL3VgCixR4jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the LinearRegression model\n",
        "linear_model = LinearRegression()"
      ],
      "metadata": {
        "id": "DDVF9Ewuybiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "linear_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "b_MHi7LZSF1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions using the testing data\n",
        "predictions = linear_model.predict(X_test)\n",
        "y_pred = predictions\n",
        "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test})\n",
        "results.head(10)"
      ],
      "metadata": {
        "id": "Bd5j3jGIR42e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "train_score = linear_model.score(X_train, y_train)\n",
        "test_score = linear_model.score(X_test, y_test)\n",
        "\n",
        "# Generate predictions for training data\n",
        "training_predictions = linear_model.predict(X_train)  # Predict on the training data\n",
        "\n",
        "r2_train = r2_score(y_train, training_predictions)\n",
        "\n",
        "# Generate predictions for testing data\n",
        "testing_predictions = linear_model.predict(X_test)   # Predict on the testing data\n",
        "\n",
        "r2_test = r2_score(y_test, testing_predictions)\n",
        "mse = mean_squared_error(y_test, testing_predictions)\n",
        "rmse = mean_squared_error(y_test, testing_predictions, squared=False)\n",
        "std = y_test.std()"
      ],
      "metadata": {
        "id": "vJ1wvxS4R4yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print metrics\n",
        "print(f\"The train_score is {train_score}.\")\n",
        "print(f\"The test_score is {test_score}.\")\n",
        "print(f\"The r2_train is {r2_train}.\")\n",
        "print(f\"The r2_test is {r2_test}.\")\n",
        "print(f\"The mean squared error is {mse}.\")\n",
        "print(f\"The root mean squared error is {rmse}.\")\n",
        "print(f\"The standard deviation is {std}.\")"
      ],
      "metadata": {
        "id": "qJMNNiFkmrEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A high MSE value indicates that the model's predictions are far from the actual values on average. The R^2 train is 0.41 and the R^2 test is 0.30. The model performed poorly"
      ],
      "metadata": {
        "id": "chgX6Mqewr81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting predicted vs actual prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue')  # Remove .values\n",
        "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted Home Prices Linear Regression')\n",
        "plt.savefig(\"linear_regression.png\") # Save the image\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ihfy72QHR4_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Support Vector Machine(SVM)\n",
        "Its primary objective is to find the optimal hyperplane that separates data points belonging to different classes in a high-dimensional space. It is used for classification and regression tasks."
      ],
      "metadata": {
        "id": "7AITM19RlcXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)"
      ],
      "metadata": {
        "id": "dXp5QoUWkwlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SVsSyRIt1eAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the training data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Initializing and fitting the SVM classifier\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "TzlgWFZaoF9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on the testing set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test})\n",
        "results.head(10)"
      ],
      "metadata": {
        "id": "aQglji2okwpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = svm_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "std_dev = np.std(y_test - y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"Root Mean Squared Error: {rmse}\")\n",
        "print(f\"R^2 Score: {r2}\")\n",
        "print(f\"Standard Deviation: {std_dev}\")"
      ],
      "metadata": {
        "id": "AQNkyvTKoNOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A lower MSE indicates better model performance. A lower RMSE values indicate better model performance. An R^2 score of 0.46 suggests that the model explains approximately 46% of the variance in the target variable. Std measures the dispersion of the actual target values around the mean. It provides context for interpreting the MSE and RMSE values."
      ],
      "metadata": {
        "id": "z-MgJHW9wPtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting predicted vs actual prices\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.scatter(y_test, y_pred, color='blue')\n",
        "plt.plot([y_pred.min(), y_pred.max()], [y_pred.min(), y_pred.max()], 'k--', lw=2)\n",
        "\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted SVM')\n",
        "plt.tight_layout()  # Adjust layout for better fit\n",
        "plt.savefig(\"SVM.png\") # Save the image\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GfMeVzoYro1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}